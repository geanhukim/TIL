# 케라스 창시자에게 배우는 딥러닝
# 목차
- [1장 : 딥러닝이란 무엇인가?]()
    - [1.1 인공 지능과 머신 러닝, 딥러닝]
    - [1.2 딥러닝 이전: 머신 러닝의 간략한 역사]
    - [1.3 왜 딥러닝일까? 왜 지금일까?]
# 1장 : 딥러닝이란 무엇인가?
## 1.1 인공 지능과 머신 러닝, 딥러닝
### 인공지능
- '컴퓨터가 '생각'할 수 있는가?'라는 아이디어에서 시작
- 인공지능이란? 보통의 사람이 수행하는 지능적인 작업을 자동화하기 위한 연구 활동
- 머신러닝과 딥러닝을 포괄하는 종합 분야
- 심볼릭 AI : 명시적인 규칙을 충분히 만들어 db에 저장하여 지식을 다루는 방법
    - 1980년대까지 많이 쓰임
- 심볼릭 AI는 체스와 같이 잘 정의된 문제는 잘 풀었지만, 이미지 분류, 음성 인식과 같은 복잡하고 불분명한 문제를 해결하기 위한 정확한 규칙을 찾기 어려웠음 -> 머신 러닝 등장
### 머신 러닝
- 전통적인 프로그래밍에서는 프로그래머가 데이터를 적절한 해답으로 바꾸기 위해 따라야 하는 규칙을 작성함
- 머신러닝은 데이터와 이에 상응하는 해답을 보고 규칙을 찾아냄
### 데이터에서 표현을 학습하기
- 머신러닝을 하기 위해 필요한 것들
    - 입력 데이터 포인트
    - 기대 출력
    - 알고리즘의 성능을 측정하는 방법
## 1.2 딥러닝 이전: 머신 러닝의 간략한 역사
## 1.3 왜 딥러닝일까? 왜 지금일까?
# 2장 : 신경망의 수학적 구성요소
## 2.1 신경망과의 첫 만남
- MNIST 손글씨 숫자 이미지 분류
``` python
from tensorflow.keras.datasets import mnist
# 훈련 세트와 테스트 세트를 구성
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()

from tensorflow import keras
from tensorflow.keras import layers
# 신경망 모델
model = keras.Sequential([
    layers.Dense(512, activation="relu"),
    layers.Dense(10, activation="softmax")
])

#컴파일 단계(옵티마이저 : 성능 향상을 위해 인풋을 기반으로 모델을 업데이트, 손실함수 : 모델의 성능을 측정, 모니터링 지표)
model.compile(optimizer="rmsprop", loss="sparse_categorical_crossentropy", metrics=["accuracy"])

# 데이터를 모델에 맞는 크기로 조정
train_images = train_images.reshape((60000, 28 * 28))
train_images = train_images.astype("float32") / 255
test_images = test_images.reshape((10000, 28 * 28))
test_images = test_images.astype("float32") / 255

# 데이터에 모델을 학습
model.fit(train_images, train_labels, epochs=5, batch_size = 128)

# 모델 평가하기
test_loss, test_acc = model.evaluate(test_images, test_labels)
```
## 2.2 신경망을 위한 데이터 표현
- 텐서 : 데이터를 위한 컨테이너
### 스칼라(랭크-0 텐서)
- 하나의 숫자만 담고 있는 텐서
- 축 개수(랭크)가 0
```python
x = np.array(12)
x # array(12)
x.ndim # 0
```
### 벡터(랭크-1 텐서)
- 숫자의 배열
- 하나의 축을 가짐
```python
x = np.array([12, 3, 6, 14, 7])
x.ndim # 1
```
### 행렬(랭크-2 텐서)
- 벡터의 배열
- 2개의 축(행과 열)을 가짐
```python
x = np.array([
    [5, 78, 2, 34, 0],
    [6, 79, 3, 35, 1],
    [7, 89, 4, 36, 2]
])
x.ndim # 2
```
### 랭크-3 텐서와 더 높은 랭크의 텐서
- 행렬들을 하나의 배열로 합치면 랭크-3 텐서
- 랭크-3 텐서를 하나의 배열로 합치면 렝크-4 텐서
### 핵심 속성
- 축의 개수(랭크)
    - 랭크-3 텐서는 3개의 축, 행렬은 2개의 축
- 크기(shape)
    - 텐서의 각 축을 따라 얼마나 많은 차원이 있는지를 나타낸 파이썬의 튜플
    - 위의 행렬의 크기는 (3, 5), 벡터의 크기는 (5,), 스칼라는 ()
- 데이터 타입
    - 텐서의 포함된 데이터의 타입
### 넘파이로 텐서 조작하기
- 슬라이싱 : 배열에 있는 특정 원소들을 선택하는 것
### 배치 데이터
- 샘플 축 : 딥러닝에서 사용하는 모든 데이터 텐서의 첫 번째 축
### 텐서의 실제 사례
- 벡터 데이터
    - 첫 번째 축 : 샘플 축
    - 두 번째 축 : 특성 축
    - ex) 3개의 특성을 가진 10만명의 인구 통계 데이터 : (100000, 3)
- 시계열 또는 시퀀스 데이터
    - 시간 축을 포함하여 랭크-3 텐서로 저장
    - 시간 축은 관례적으로 두 번째 축
- 이미지 데이터
    - 관례상 랭크-3 텐서로 저장
    - ex) 128 개의 256 * 256크기의 컬러 이미지 : (128, 256, 256, 2)
- 비디오 데이터
    - 랭크-5 텐서
## 2.3 신경망의 톱니바퀴: 텐서 연산